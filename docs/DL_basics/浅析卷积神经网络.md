# [深入浅出卷积神经网络CNN](https://mp.weixin.qq.com/s?__biz=MzIyNjM2MzQyNg==&mid=2247499511&idx=1&sn=a420a254f767241e6b3c40e55b28a963&scene=21#wechat_redirect)

![](https://mmbiz.qpic.cn/mmbiz_png/vI9nYe94fsHlsIZib4QU2kdcKN9xdz0XBdAvJibWlY7SvTHLl6mJVRIL5knb6oBmCn13XqG4OcpCD6y4iaZPzrSYQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

卷积神经网络（Convolutional Neural Network, CNN）是一类特殊的人工神经网络，是深度学习中重要的一个分支。在图像分类时，常常面临着图像大，物体的形态、位置不同等问题，这就给普通的神经网络带来了难题，而CNN就是来解决这个问题，它的精度和速度比传统计算学习算法高很多。特别是在计算机视觉领域，CNN是解决图像分类、图像检索、物体检测和语义分割的主流模型。

CNN每一层由众多的卷积核组成，每个卷积核对输入的像素进行卷积操作，得到下一次的输入。随着网络层的增加卷积核会逐渐扩大感受野，并缩减图像的尺寸。

卷积神经网络与普通神经网络非常相似，它们都由具有可学习的权重和偏置常量的神经元组成。每个神经元都接收一些输入，并做一些点积计算，输出是每个分类的分数，普通神经网络里的一些计算技巧到这里依旧适用。

两者的不同点在于，卷积神经网络默认输入是图像，可以让我们把特定的性质编码入网络结构，使我们的前馈函数更加有效率，并减少了大量参数。



这是一篇不错的介绍https://mp.weixin.qq.com/s/Kgt7fyzkcfEClcI_xgvddw



## **1. 具有三维体积的神经元(3D volumes of neurons)**

卷积神经网络利用输入图片的特点，把神经元设计成三个维度 ：width, height, depth。比如输入的图片大小是 32 × 32 × 3 (rgb)，那么输入神经元就也具有 32×32×3 的维度。下面是传统神经网络的示意图：

![img](https://mmbiz.qpic.cn/mmbiz_png/vI9nYe94fsFtXNXWGT70mokV6vkgUD9jp8BJjCQSLMX31kCTVIguibekc39w2yKZzwZbmq5Zo01XogmEoBY2BEg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

一个卷积神经网络由很多层组成，它们的输入是三维的，输出也是三维的，有的层有参数，有的层不需要参数。卷积神经网络的示意图如下：

![img](https://mmbiz.qpic.cn/mmbiz_png/vI9nYe94fsFtXNXWGT70mokV6vkgUD9jZuYtpqPaQSKLWoqqhTmicjpzweMTAXruRcLqS6w8iaJqDwe9JyzaCnqQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

## **2. 卷积神经网络结构**

### **2.1 卷积层（Convolutional layer）**

卷积神经网路中每层卷积层由若干卷积单元组成，每个卷积单元的参数都是通过反向传播算法优化得到的。卷积运算的目的是提取输入的不同特征，第一层卷积层可能只能提取一些低级的特征如边缘、线条和角等层级，更多层的网络能从低级特征中迭代提取更复杂的特征。

![img](../img/浅析卷积神经网络/卷积层.jpg)

那如何提前知道卷积核呢？假如是人脸识别这样成千上万个特征的图片，我们就没办法提前知道什么是合适的卷积核。其实也没必要知道，因为选择什么样的卷积核，完全可以通过训练不断优化。初始时只需要随机设置一些卷积核，通过训练，模型其实自己可以学习到合适的卷积核，这也是卷积神经网络模型强大的地方。

以灰度图像为例进行讲解：从一个小小的权重矩阵，也就是卷积核（kernel）开始，让它逐步在二维输入数据上“扫描”。卷积核“滑动”的同时，计算权重矩阵和扫描所得的数据矩阵的乘积，然后把结果汇总成一个输出像素。

![img](../img/浅析卷积神经网络/v2-6428cf505ac1e9e1cf462e1ec8fe9a68_b.webp)

![img](../img/浅析卷积神经网络/v2-705305fee5a050575544c64067405fce_b.webp)

深度学习里面所谓的卷积运算，其实它被称为**互相关（cross-correlation）运算：**将图像矩阵中，从左到右，由上到下，取与滤波器同等大小的一部分，每一部分中的值与滤波器中的值对应相乘后求和，最后的结果组成一个矩阵，其中没有对核进行翻转。

**填充（Padding）**

前面可以发现，输入图像与卷积核进行卷积后的结果中损失了部分值，输入图像的边缘被“修剪”掉了（边缘处只检测了部分像素点，丢失了图片边界处的众多信息）。这是因为边缘上的像素永远不会位于卷积核中心，而卷积核也没法扩展到边缘区域以外。这个结果我们是不能接受的，有时我们还希望输入和输出的大小应该保持一致。为解决这个问题，可以在进行卷积操作前，对原矩阵进行边界**填充（Padding）**，也就是在矩阵的边界上填充一些值，以增加矩阵的大小，通常都用“$0$”来进行填充的。

![img](https://picb.zhimg.com/v2-2a2307d5c20551f1a3e8458c7070cf16_b.webp)

通过填充的方法，当卷积核扫描输入数据时，它能延伸到边缘以外的伪像素，从而使输出和输入size相同。

常用的两种padding：

**（1）valid padding**：不进行任何处理，只使用原始图像，不允许卷积核超出原始图像边界

**（2）same padding**：进行填充，允许卷积核超出原始图像边界，并使得卷积后结果的大小与原来的一致

**步长（Stride）**

滑动卷积核时，我们会先从输入的左上角开始，每次往左滑动一列或者往下滑动一行逐一计算输出，我们将每次滑动的行数和列数称为Stride，在之前的图片中，Stride=1；在下图中，Stride=2。

![img](https://picb.zhimg.com/v2-294159b043a917ea622e1794b4857a34_b.webp)

卷积过程中，有时需要通过padding来避免信息损失，有时也要在卷积时通过设置的**步长（Stride）**来压缩一部分信息，或者使输出的尺寸小于输入的尺寸。

![img](../img/浅析卷积神经网络/v2-c14af9d136b1431018146118492b0856_b.webp)

**Stride的作用：**是成倍缩小尺寸，而这个参数的值就是缩小的具体倍数，比如步幅为2，输出就是输入的1/2；步幅为3，输出就是输入的1/3。以此类推。

**卷积核的大小一般为奇数\*奇数** ：$1*1$，$3*3$，$5*5$，$7*7$都是最常见的。**这是为什么呢？**为什么没有偶数*偶数​？

**（1）更容易padding**

在卷积时，我们有时候需要卷积前后的尺寸不变。这时候我们就需要用到padding。假设图像的大小，也就是被卷积对象的大小为$n*n$，卷积核大小为$k*k$，padding的幅度设为$(k-1)/2$时，卷积后的输出就为$[n-k+2*((k-1)/2)]/1+1=n$，即卷积输出为$n*n$，保证了卷积前后尺寸不变。但是如果$k$是偶数的话，$(k-1)/2$就不是整数了。

**（2）更容易找到卷积锚点**

在CNN中，进行卷积操作时一般会以卷积核模块的一个位置为基准进行滑动，这个基准通常就是卷积核模块的中心。若卷积核为奇数，卷积锚点很好找，自然就是卷积模块中心，但如果卷积核是偶数，这时候就没有办法确定了，让谁是锚点似乎都不怎么好。

**卷积的计算公式**

**输入图片的尺寸：**一般用 $n * n$ 表示输入的image大小。**卷积核的大小：**一般用 $f*f$ 表示卷积核的大小。

**填充（Padding）：**一般用 $p$来表示填充大小。

**步长(Stride)：**一般用 $s$ 来表示步长大小。

**输出图片的尺寸：**一般用 $o$ 来表示。如果已知  $n$、 $f$ 、  、 $p$、$s$ 可以求得 $o$ ，**计算公式如下：**$o= \lfloor \frac{n+2p-f}{s} \rfloor +1$其中"$\lfloor $ $  \rfloor$"是向下取整符号，用于结果不是整数时进行向下取整。

**多通道卷积**上述例子都只包含一个输入通道。实际上，大多数输入图像都有 RGB 3个通道。

![img](../img/浅析卷积神经网络/v2-fc70463d7f82f7268ee23b7235515f4a_720w.jpg)

这里就要涉及到“卷积核”和“filter”这两个术语的区别。在只有一个通道的情况下，“卷积核”就相当于“filter”，这两个概念是可以互换的。但在一般情况下，它们是两个完全不同的概念。**每个“filter”实际上恰好是“卷积核”的一个集合**，在当前层，每个通道都对应一个卷积核，且这个卷积核是独一无二的。

**多通道卷积的计算过程：**将矩阵与滤波器对应的每一个通道进行卷积运算，最后相加，形成一个单通道输出，加上偏置项后，我们得到了一个最终的单通道输出。如果存在多个filter，这时我们可以把这些最终的单通道输出组合成一个总输出。这里我们还需要**注意**一些问题——滤波器的通道数、输出特征图的通道数。

**某一层滤波器的通道数 = 上一层特征图的通道数。**如上图所示，我们输入一张 $6\times6\times3$ 的RGB图片，那么滤波器（$3\times3\times3$）也要有三个通道。

**某一层输出特征图的通道数 = 当前层滤波器的个数。**如上图所示，当只有一个filter时，输出特征图（ ）的通道数为1；当有2个filter时，输出特征图（ $4\times4\times2$）的通道数为2。

### **2.2 池化层（Pooling layer）**

通常在卷积层之后会得到维度很大的特征，将特征切成几个区域，取其最大值或平均值，得到新的、维度较小的特征。

池化即下采样，目的是为了减少特征图，本质上其实就是对数据进行一个缩小。因为我们知道，比如人脸识别，通过卷积操作得到成千上万个feature map，每个feature map也有很多的像素点，这些对于后续的运算的时间会变得很长。池化其实就是对每个输入的feature map进一步提炼的过程。如下图所示，原来4X4的feature map经过池化操作之后就变成了更小的2*2的矩阵。池化的方法包括max pooling最大池化（取最大值）以及average pooling平均池化（取平均值）等等。

池化操作对每个深度切片独立，规模一般为 2＊2，相对于卷积层进行卷积运算，池化层进行的运算一般有以下几种：

- 最大池化（Max Pooling）。取4个点的最大值。这是最常用的池化方法。
- 平均池化（Mean Pooling）。取4个点的均值。
- 高斯池化。借鉴高斯模糊的方法。不常用。
- 可训练池化。训练函数 ff ，接受4个点为输入，出入1个点。不常用。

最常见的池化层是规模为2*2， 步幅为2，对输入的每个深度切片进行下采样。每个MAX操作对四个数进行，如下图所示：

![img](../img/浅析卷积神经网络/池化层.jpg)

池化过程类似于卷积过程，如上图所示，表示的就是对一个 $4\times4$ feature map邻域内的值，用一个  $2\times2$的filter，步长为2进行‘扫描’，选择最大值输出到下一层，这叫做 Max Pooling。

max pooling常用的 $s=2,f=2$ ，的效果：特征图高度、宽度减半，通道数不变。

还有一种叫**平均池化（Average Pooling）**,就是从以上取某个区域的最大值改为求这个区域的平均值，其具体操作过程如下：

![img](https://pic2.zhimg.com/80/v2-a47095dd0902990d387e21ae24e6f0b9_720w.jpg)

如上图所示，表示的就是对一个 $4\times4$ feature map邻域内的值，用一个 $2\times2$ 的filter，步长为2进行‘扫描’，计算平均值输出到下一层，这叫做 Mean Pooling。

**池化层没有参数**

**池化的作用：**

（1）保留主要特征的同时减少参数和计算量，防止过拟合。

（2）invariance(不变性)，这种不变性包括translation(平移)，rotation(旋转)，scale(尺度)。

Pooling 层说到底还是一个特征选择，信息过滤的过程。也就是说我们损失了一部分信息，这是一个和计算性能的一个妥协，随着运算速度的不断提高，我认为这个妥协会越来越小。

现在有些网络都开始少用或者不用pooling层了。

池化操作将保存深度大小不变。如果池化层的输入单元大小不是二的整数倍，一般采取边缘补零（zero-padding）的方式补成2的倍数，然后再池化。

**2.3 非线性激活函数**

神经的非线性激活化函数，用于增加网络的非线性分割能力，一般用Relu函数。同时也可以叫做Normalization，就是将矩阵中负数的值转成0,也就是使用ReLu的激活函数进行负数变为0的操作。ReLu函数本质上就是max（0，x）。这一步其实也是为了方便运算。

### **2.4 全连接层（ Fully-Connected layer）**

完全连接层是一个传统的多层感知器，它在输出层使用 softmax 激活函数。把所有局部特征结合变成全局特征，用来计算最后每一类的得分。卷积、ReLu、pooling，不断重复其实也就基本上构成了卷积神经网络的框架。

全连接层就是将最后一层卷积得到的特征图（矩阵）展开成一维向量，并为分类器提供输入。最开始看到这个全连接层，我就很是疑问：它是怎么做的呢？一个列子：

![img](../img/浅析卷积神经网络/v2-278687a5273635b6c78e79e854a11696_720w.jpg)

我们输入一个 $28\times28$ 的灰度图像，经过卷积层和池化层输出20个的图像，然后通过了一个全连接层变成了$1\times100$的向量。

这是怎么做到的呢？很简单，**可以理解为在中间做了一次卷积**。我们用一个12x12x20的filter 去卷积激活函数的输出，得到的结果就是一个fully connected layer 的一个神经元的输出，这个输出就是一个值。因为我们有100个神经元，所以输出一个$1\times100$ 的向量。**我们实际就是用一个$12\times12\times20\times100$的卷积层去卷积激活函数的输出，最终得到 $1\times100$的向量。**

**全连接层的作用：**全连接层在整个网络卷积神经网络中起到“分类器”的作用。如果说卷积层、池化层和激活函数等操作是将原始数据映射到隐层特征空间的话（特征提取+选择的过程），**全连接层则起到将学到的特征表示映射到样本的标记空间的作用**。换句话说，**就是把特征整合到一起**（高度提纯特征）**，方便交给最后的分类器或者回归。**

**全连接层存在问题：**参数冗余（仅全连接层参数就可占整个网络参数80%左右），降低了训练的速度，容易过拟合。

**CNN（带有FC层）输入图片尺寸是固定的原因：**全连接层要求固定的输入维度（如4096）

**CNN支持任意尺寸输入图像的方法：**（1）使用全局平均池化层或卷积层替换FC层（2）在卷积层和FC层之间加入空间金字塔池化

另一个参考：https://blog.csdn.net/quiet_girl/article/details/84579038

一个卷积神经网络各层应用实例：

![img](https://mmbiz.qpic.cn/mmbiz_png/vI9nYe94fsFtXNXWGT70mokV6vkgUD9jbPjwf35Z0iaH9bcpeEKJyG9yb6U5ZqRRCianXMvDprlz98M8H7aLWFrA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

## **CNN常见模型**

**1. 卷积神经网络基础：LeNet5**

手写字体识别模型LeNet5诞生于1994年，是最早的卷积神经网络之一。LeNet5通过巧妙的设计，利用卷积、参数共享、池化等操作提取特征，避免了大量的计算成本，最后再使用全连接神经网络进行分类识别，这个网络也是最近大量神经网络架构的起点。

如下图所示为LeNet网络结构，总共有7层网络（不含输入层），2个卷积层、2个池化层、3个全连接层。

![img](https://mmbiz.qpic.cn/mmbiz_png/vI9nYe94fsH5zh1sRg16h4kXf7ibOXIUDVumhwGnst6vJZqkpSuORq02as8WfeDgSxMicLr6cMlxL4tEuWoib8icBA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

LeNet分为卷积层块和全连接层块两个部分。下面我们分别介绍这两个模块。卷积层块里的基本单位是卷积层后接最大池化层：卷积层用来识别图像里的空间模式，如线条和物体局部，之后的最大池化层则用来降低卷积层对位置的敏感性。卷积层块由两个这样的基本单位重复堆叠构成。在卷积层块中，每个卷积层都使用5*5的窗口，并在输出上使用sigmoid激活函数。第一个卷积层输出通道数为6，第二个卷积层输出通道数则增加到16。这是因为第二个卷积层比第一个卷积层的输入的高和宽要小，所以增加输出通道使两个卷积层的参数尺寸类似。卷积层块的两个最大池化层的窗口形状均为2*2，且步幅为2。由于池化窗口与步幅形状相同，池化窗口在输入上每次滑动所覆盖的区域互不重叠。

卷积层块的输出形状为(批量大小, 通道, 高, 宽)。当卷积层块的输出传入全连接层块时，全连接层块会将小批量中每个样本变平（flatten）。也就是说，全连接层的输入形状将变成二维，其中第一维是小批量中的样本，第二维是每个样本变平后的向量表示，且向量长度为通道、高和宽的乘积。全连接层块含3个全连接层。它们的输出个数分别是120、84和10，其中10为输出的类别个数。

在卷积层块中输入的高和宽在逐层减小。卷积层由于使用高和宽均为5的卷积核，从而将高和宽分别减小4，而池化层则将高和宽减半，但通道数则从1增加到16。全连接层则逐层减少输出个数，直到变成图像的类别数10。

![img](https://mmbiz.qpic.cn/mmbiz_png/vI9nYe94fsH5zh1sRg16h4kXf7ibOXIUDDRkdnjeIXDibcfdBglsA0lbT46bfx5qyJtVBQ9QEciaFSG3EWUkaib9ug/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1&retryload=1)

通过多次卷积和池化，CNN的最后一层将输入的图像像素映射为具体的输出。如在分类任务中会转换为不同类别的概率输出，然后计算真实标签与CNN模型的预测结果的差异，并通过反向传播更新每层的参数，并在更新完成后再次前向传播，如此反复直到训练完成 。 

一个数字识别的效果如图所示：

![img](https://mmbiz.qpic.cn/mmbiz_png/vI9nYe94fsH5zh1sRg16h4kXf7ibOXIUDEv4OY9mBUu8Q2LkIKgYI9mYDsySVYLfuuKlFb6bvdg0wjUaFC7o70g/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

**2. 卷积神经网络进阶**

随着网络结构的发展，研究人员最初发现网络模型结构越深、网络参数越多模型的精度更优。比较典型的是AlexNet、VGG、InceptionV3和ResNet的发展脉络。  

![img](https://mmbiz.qpic.cn/mmbiz_png/vI9nYe94fsH5zh1sRg16h4kXf7ibOXIUDpHicEBMqsXYBxkvWMnvPw77DtwL5JKqyaiaFZ5ConwGicT6SAKCOiaBiacw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

**2.1 AlexNet(2012)**

2012年，AlexNet横空出世。这个模型的名字来源于论文第一作者的姓名Alex Krizhevsky。AlexNet使用了8层卷积神经网络，并以很大的优势赢得了ImageNet 2012图像识别挑战赛。它首次证明了学习到的特征可以超越手工设计的特征，从而一举打破计算机视觉研究的现状。

![img](https://mmbiz.qpic.cn/mmbiz_png/vI9nYe94fsH5zh1sRg16h4kXf7ibOXIUD9WSG9oj4BmGQGwwVYP0tmaG4CRaKWtfeQ6QoXfEFjbwZP64YUBjicVQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

与相对较小的LeNet相比，AlexNet包含8层变换，其中有5层卷积和2层全连接隐藏层，以及1个全连接输出层。AlexNet在LeNet的基础上增加了3个卷积层。但AlexNet作者对它们的卷积窗口、输出通道数和构造顺序均做了大量的调整，通过丢弃法来控制全连接层的模型复杂度；将sigmoid激活函数改成了更加简单的ReLU激活函数；引入了大量的图像增广，如翻转、裁剪和颜色变化，从而进一步扩大数据集来缓解过拟合。虽然AlexNet指明了深度卷积神经网络可以取得出色的结果，但并没有提供简单的规则以指导后来的研究者如何设计新的网络。

**2.2 VGG-16(2014)** 

VGG，它的名字来源于论文作者所在的实验室Visual Geometry Group。VGG提出了可以通过重复使用简单的基础块来构建深度模型的思路。VGG16相比AlexNet的一个改进是采用连续的几个3x3的卷积核代替AlexNet中的较大卷积核（11x11，7x7，5x5），通过重复使用简单的基础块来构建深度模型的思路 。VGG16包含了16个隐藏层（13个卷积层和3个全连接层）。**VGG的结构图如下：**

![img](https://mmbiz.qpic.cn/mmbiz_jpg/vI9nYe94fsE7aLMjp0ernTUbEhpRE8WIeVibyyyrAANywOj7IhOyudBC02OulVxqLhKRL5ykaOSyiaXGVzZqm3GA/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

**VGG块的组成规律是**：连续使用数个相同的填充为1、窗口形状为3*3的卷积层后接上一个步幅为2、窗口形状为2*2的最大池化层。卷积层保持输入的高和宽不变，而池化层则对其减半。我们使用**vgg_block**函数来实现这个基础的VGG块，它可以指定卷积层的数量和输入输出通道数。

> 对于给定的感受野（与输出有关的输入图片的局部大小），采用堆积的小卷积核优于采用大的卷积核，因为可以增加网络深度来保证学习更复杂的模式，而且代价还比较小（参数更少）。例如，在VGG中，使用了3个3x3卷积核来代替7x7卷积核，使用了2个3x3卷积核来代替5*5卷积核，这样做的主要目的是在保证具有相同感知野的条件下，提升了网络的深度，在一定程度上提升了神经网络的效果。

与AlexNet和LeNet一样，VGG网络由卷积层模块后接全连接层模块构成。卷积层模块串联数个vgg_block，其超参数由变量conv_arch定义。该变量指定了每个VGG块里卷积层个数和输入输出通道数。全连接模块则跟AlexNet中的一样。

现在我们构造一个VGG网络。它有5个卷积块，前2块使用单卷积层，而后3块使用双卷积层。第一块的输入输出通道分别是1（因为下面要使用的Fashion-MNIST数据的通道数为1）和64，之后每次对输出通道数翻倍，直到变为512。因为这个网络使用了8个卷积层和3个全连接层，所以经常被称为VGG-11。

可以看到，每次我们将输入的高和宽减半，直到最终高和宽变成7后传入全连接层。与此同时，输出通道数每次翻倍，直到变成512。因为每个卷积层的窗口大小一样，所以每层的模型参数尺寸和计算复杂度与输入高、输入宽、输入通道数和输出通道数的乘积成正比。VGG这种高和宽减半以及通道翻倍的设计使得多数卷积层都有相同的模型参数尺寸和计算复杂度。

VGG：通过重复使⽤简单的基础块来构建深度模型。  Block: 数个相同的填充为1、窗口形状为3×3的卷积层,接上一个步幅为2、窗口形状为2×2的最大池化层。卷积层保持输入的高和宽不变，而池化层则对其减半。VGG和AlexNet的网络图对比如下：

![img](https://mmbiz.qpic.cn/mmbiz_png/vI9nYe94fsH5zh1sRg16h4kXf7ibOXIUDntJ234bhJGJh4xGod3qWGw5eRvX7CYT7gopZhHDtSliaKe45xRIk7Fw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

![img](https://mmbiz.qpic.cn/mmbiz_png/vI9nYe94fsH5zh1sRg16h4kXf7ibOXIUDzBjYOvL9SQP2fGwube16uxyozyb02YDR99UnO5zvG8Kiac0xB7WujZw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)**小结**：VGG-11通过5个可以重复使用的卷积块来构造网络。根据每块里卷积层个数和输出通道数的不同可以定义出不同的VGG模型。   

**2.3 网络中的网络（NiN）**

LeNet、AlexNet和VGG：先以由卷积层构成的模块充分抽取空间特征，再以由全连接层构成的模块来输出分类结果。NiN：串联多个由卷积层和“全连接”层构成的小⽹络来构建⼀个深层⽹络。 ⽤了输出通道数等于标签类别数的NiN块，然后使⽤全局平均池化层对每个通道中所有元素求平均并直接用于分类。 

![img](https://mmbiz.qpic.cn/mmbiz_png/vI9nYe94fsH5zh1sRg16h4kXf7ibOXIUDSGwVrpSiaM6ibB5AuNKXXaGv8ZiaW8HmqvCqmnRicrQaOIZakqCFicNRPiaQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

**2.4 含并行连结的网络（GoogLeNet）**

在2014年的ImageNet图像识别挑战赛中，一个名叫GoogLeNet的网络结构大放异彩。它虽然在名字上向LeNet致敬，但在网络结构上已经很难看到LeNet的影子。GoogLeNet吸收了NiN中网络串联网络的思想，并在此基础上做了很大改进。在随后的几年里，研究人员对GoogLeNet进行了数次改进，本节将介绍这个模型系列的第一个版本。

- 由Inception基础块组成。 
- Inception块相当于⼀个有4条线路的⼦⽹络。它通过不同窗口形状的卷积层和最⼤池化层来并⾏抽取信息，并使⽤1×1卷积层减少通道数从而降低模型复杂度。 
- 可以⾃定义的超参数是每个层的输出通道数，我们以此来控制模型复杂度。 

Inception块GoogLeNet中的基础卷积块叫作Inception块，得名于同名电影《盗梦空间》（Inception）。与上一节的NiN块相比，这个基础块在结构上更加复杂。

![img](https://mmbiz.qpic.cn/mmbiz_png/vI9nYe94fsH5zh1sRg16h4kXf7ibOXIUDpahFMicaD1N45HqXqcybG544fuj0SrCiaoYSTaZCkRcXibQJNI5VJhBFA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

**2.5 残差网络（ResNet-50）**    

深度学习的问题：深度CNN网络达到一定深度后再一味地增加层数并不能带来进一步地分类性能提高，反而会招致网络收敛变得更慢，准确率也变得更差。- - -残差块（Residual Block）恒等映射：

- 左边：f(x)=x；
- 右边：f(x)-x=0 （易于捕捉恒等映射的细微波动）。

![img](https://mmbiz.qpic.cn/mmbiz_png/vI9nYe94fsH5zh1sRg16h4kXf7ibOXIUDGOHRcsQhsticS1Pobj9UiciciciaQqs6PaUIibeGKSwZbnjNKbpRlicBApjicA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

ResNet的前两层跟之前介绍的GoogLeNet中的一样：在输出通道数为64、步幅为2的7*7卷积层后接步幅为2的3*3的最大池化层。不同之处在于ResNet每个卷积层后增加的批量归一化层。ResNet-50网络结构如下：

![img](https://mmbiz.qpic.cn/mmbiz_png/vI9nYe94fsH5zh1sRg16h4kXf7ibOXIUDoxrPysUiaq6mm9jv1CgIYkqyoHHjv2rmOY1xqVUhQJoEQum5Nicvp4CQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)