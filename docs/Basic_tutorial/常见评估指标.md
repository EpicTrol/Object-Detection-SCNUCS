# 一般问题评价指标

什么是评估指标：

>评估指标即是我们对于一个模型效果的数值型量化。（有点类似与对于一个商品评价打分，而这是针对于模型效果和理想效果之间的一个打分）

一般来说分类和回归问题的评价指标有如下一些形式：

#### 分类算法常见的评估指标如下：
* 对于二类分类器/分类算法，评价指标主要有accuracy， [Precision，Recall，F-score，Pr曲线]，ROC-AUC曲线。
* 对于多类分类器/分类算法，评价指标主要有accuracy， [宏平均和微平均，F-score]。

#### 对于回归预测类常见的评估指标如下:
* 平均绝对误差（Mean Absolute Error，MAE），均方误差（Mean Squared Error，MSE），平均绝对百分误差（Mean Absolute Percentage Error，MAPE），均方根误差（Root Mean Squared Error）， R2（R-Square）

下面进行详细介绍：

1. **平均绝对误差（Mean Absolute Error，MAE）**，能更好地反映预测值与真实值误差的实际情况：

$$
MAE=\frac{1}{N} \sum_{i=1}^{N}\left|y_{i}-\hat{y}_{i}\right|
$$



2. **均方误差（Mean Squared Error，MSE）**：

$$
MSE=\frac{1}{N} \sum_{i=1}^{N}\left(y_{i}-\hat{y}_{i}\right)^{2}
$$

3. RMSE(Root Mean Squard Error)

$$
RMSE(y,f(x))=\frac{1}{1+MSE(y,f(x))}
$$

4. **R2（R-Square）的公式为**：

   残差平方和：
   $$
   SS_{res}=\sum\left(y_{i}-\hat{y}_{i}\right)^{2}
   $$
   
   总平均值:
   
   $$
   SS_{tot}=\sum\left(y_{i}-\overline{y}_{i}\right)^{2}
   $$
   
   其中$\overline{y}$表示$y$的平均值,得到$R^2$表达式为：
   $$
   R^{2}=1-\frac{SS_{res}}{SS_{tot}}=1-\frac{\sum\left(y_{i}-\hat{y}_{i}\right)^{2}}{\sum\left(y_{i}-\overline{y}\right)^{2}}
   $$
   $R^2$用于度量因变量的变异中可由自变量解释部分所占的比例，取值范围是 0~1，$R^2$越接近1,表明回归平方和占总平方和的比例越大,回归线与各观测点越接近，用x的变化来解释y值变化的部分就越多,回归的拟合程度就越好。所以$R^2$也称为拟合优度（Goodness of Fit）的统计量。
   
   $y_{i}$表示真实值，$\hat{y}_{i}$表示预测值，$\overline{y}_{i}$表示样本均值。得分越高拟合效果越好。

5. 混淆矩阵

   | 混淆矩阵            | Predicted as Positive | Predicted as Negative |
   | ------------------- | --------------------- | --------------------- |
   | Labeled as Positive | True Positive(TP)     | False Negative(FN)    |
   | Labeled as Negative | False Positive(FP)    | True Negative(TN)     |

* 真正例(True Positive, TP):真实类别为正例, 预测类别为正例
* 假负例(False Negative, FN): 真实类别为正例, 预测类别为负例
* 假正例(False Positive, FP): 真实类别为负例, 预测类别为正例 
* 真负例(True Negative, TN): 真实类别为负例, 预测类别为负例

* 真正率(True Positive Rate, TPR): 被预测为正的正样本数 / 正样本实际数

$$
TPR=\frac{TP}{TP+FN}
$$

* 假负率(False Negative Rate, FNR): 被预测为负的正样本数/正样本实际数

$$
FNR=\frac{FN}{TP+FN}
$$

* 假正率(False Positive Rate, FPR): 被预测为正的负样本数/负样本实际数，

$$
FPR=\frac{FP}{FP+TN}
$$

* 真负率(True Negative Rate, TNR): 被预测为负的负样本数/负样本实际数，

$$
TNR=\frac{TN}{FP+TN}
$$

* 准确率(Accuracy)

$$
ACC=\frac{TP+TN}{TP+FN+FP+TN}
$$

* 精准率

$$
P=\frac{TP}{TP+FP}
$$

* 召回率

$$
R=\frac{TP}{TP+FN}
$$

* F1-Score

$$
\frac{2}{F_1}=\frac{1}{P}+\frac{1}{R}
$$

* ROC

  ROC曲线的横轴为“假正例率”，纵轴为“真正例率”. 以FPR为横坐标，TPR为纵坐标，那么ROC曲线就是改变各种阈值后得到的所有坐标点 (FPR,TPR) 的连线，画出来如下。红线是随机乱猜情况下的ROC，曲线越靠左上角，分类器越佳. 

* AUC(Area Under Curve)

  AUC就是ROC曲线下的面积. 真实情况下，由于数据是一个一个的，阈值被离散化，呈现的曲线便是锯齿状的，当然数据越多，阈值分的越细，”曲线”越光滑. 

  图片

  用AUC判断分类器（预测模型）优劣的标准:

  + AUC = 1 是完美分类器，采用这个预测模型时，存在至少一个阈值能得出完美预测。绝大多数预测的场合，不存在完美分类器.

  + 0.5 < AUC < 1，优于随机猜测。这个分类器（模型）妥善设定阈值的话，能有预测价值.

  + AUC < 0.5，比随机猜测还差；但只要总是反预测而行，就优于随机猜测.

6. 