{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用Pytorch框架的CNN网络实现手写数字（MNIST）识别\n",
    "目录结构：\n",
    "```\n",
    "├─pytorch-mnist（这个可自己随机改）\n",
    "│  ├─data              MNIST数据集\n",
    "│  ├─checkpoint\n",
    "│  │  ├─model-mnist.pth 保存的模型\n",
    "│  ├─mnist.ipynb\n",
    "│  ├─mnist.ipynb\t   Jupyter Notebook版文件\n",
    "│  ├─mnist.py\t\t  py版文件\t\n",
    "│  ├─mnist.jpg\t\t py文件运行截图\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T15:33:11.153211Z",
     "start_time": "2020-06-01T15:33:11.149221Z"
    }
   },
   "source": [
    "## 1. 导入所需包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T12:08:09.960184Z",
     "start_time": "2020-06-02T12:07:57.846909Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 参数配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T12:08:10.541354Z",
     "start_time": "2020-06-02T12:08:09.961172Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512 # 大概需要2G的显存\n",
    "EPOCHS = 20 # 总共训练批次\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # gpu更快"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 准备数据\n",
    "+ MNIST数据集包含60000个训练集和10000测试数据集。分为图片和标签，图片是**28*28的一维灰度图**，标签为0~9共10个数字\n",
    "+ 使用`torchvision`加载MNIST\n",
    "+ 由于之前已下载了数据故download设为False，[数据下载慢的解决方法](https://blog.csdn.net/qq_43280818/article/details/104241326)\n",
    "+ 一个样本的格式为[data,label]，第一个存放数据，第二个存放标签\n",
    "+ 可加上num_workers参数，用多个子进程加载数据，可加快数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T12:08:11.034554Z",
     "start_time": "2020-06-02T12:08:10.543346Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train = True, download = False,\n",
    "        transform = transforms.Compose([\n",
    "                  transforms.ToTensor(),\n",
    "                  transforms.Normalize((0.1037,), (0.3081,))\n",
    "              ])),\n",
    "batch_size = BATCH_SIZE, shuffle = True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train = False, \n",
    "        transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.1037,), (0.3081,))\n",
    "])),\n",
    "batch_size = BATCH_SIZE, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设置batch_size=512后，加载器中的基本单位是一个batch的数据，即一个dataloader是一个batch的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T12:08:11.042526Z",
     "start_time": "2020-06-02T12:08:11.035542Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loader len: 118\n",
      "test_loader len: 20\n"
     ]
    }
   ],
   "source": [
    "print('train_loader len:',len(train_loader)) #60000/512\n",
    "print('test_loader len:',len(test_loader)) #10000/512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 模型构建\n",
    "\n",
    "1. 定义CNN网络\n",
    "  + Conv2d参数\n",
    "\n",
    "    in_channels(int) – 必选 输入信号的通道数目，由于图像为单通道灰度图故初始为1\n",
    "\n",
    "    out_channels(int) – 必选 卷积产生的通道数目\n",
    "\n",
    "    kerner_size(int or tuple) - 必选 卷积核的尺寸\n",
    "\n",
    "    stride(int or tuple, optional) - 可选 卷积步长，默认为1\n",
    "\n",
    "    padding(int or tuple, optional) - 可选 设置在所有边界增加值为0的边距的大小，也就是在feature map 外围增加几圈 0 ，默认为0，例如3x3在外围补1圈0就变成5x5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T12:08:11.055549Z",
     "start_time": "2020-06-02T12:08:11.043523Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #1*1*28*28\n",
    "        self.conv1 = nn.Conv2d(1, 10, 5) #5x5 输入1 输出10（10个数字） \n",
    "        self.conv2 = nn.Conv2d(10, 20, 3) #3x3 \n",
    "        self.fc1 = nn.Linear(20 * 10 * 10, 500) # 全连接 输出500x1\n",
    "        self.fc2 = nn.Linear(500, 10) # 10分类（数字0~9） 输出10x1\n",
    "        \n",
    "    def forward(self, x):\n",
    "        in_size = x.size(0) # batchsize\n",
    "        out= self.conv1(x) # 第一层卷积输出 shape 1* 10 * 24 *24 （28-5+1）\n",
    "        out = F.relu(out)\n",
    "        out = F.max_pool2d(out, 2, 2) # 最大池化层 1* 10 * 12 * 12（24/2）\n",
    "        out = self.conv2(out) # 第二层卷积输出1* 20 * 10 * 10（12-3+1）\n",
    "        out = F.relu(out)\n",
    "        out = out.view(in_size, -1) # 1 * 2000 输出前数据预处理，压缩展平卷积 将 in_size（即batch_size）个Sample拉成一维。-1：列自适应\n",
    "        out = self.fc1(out) # 1 * 500\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out) # 1 * 10\n",
    "        out = F.log_softmax(out, dim = 1) #将数据的范围改到[0, 1]之内，表概率，维度不变\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 损失和优化函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T12:18:29.187580Z",
     "start_time": "2020-06-02T12:18:20.690210Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=2000, out_features=500, bias=True)\n",
      "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Digraph.gv.pdf'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchviz import make_dot\n",
    "model = CNN().to(DEVICE) # 模型实例化\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) \n",
    "print(model)\n",
    "p=make_dot(model(torch.rand(10,1,28,28).cuda()))\n",
    "p.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T11:43:17.207494Z",
     "start_time": "2020-06-01T11:43:17.197481Z"
    }
   },
   "source": [
    "## 4. 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T14:43:25.200764Z",
     "start_time": "2020-06-01T14:43:25.190817Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # 清除上个batch的梯度信息 即清零所有参数的梯度缓存 否则梯度将会与已有的梯度累加\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 前向+后向+优化\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward() # 随机梯度的反向传播\n",
    "        optimizer.step() # 更新参数\n",
    "\n",
    "        if (batch_idx + 1) % 30 == 0:# 每30个batch进行输出\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T14:45:53.423953Z",
     "start_time": "2020-06-01T14:45:52.756117Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.isdir('checkpoint'):\n",
    "    os.mkdir('checkpoint')\n",
    "torch.save(model.state_dict(), 'checkpoint/mnist_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T14:46:12.601061Z",
     "start_time": "2020-06-01T14:46:12.590091Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss =0\n",
    "    correct = 0\n",
    "    with torch.no_grad(): # 进行评测的时候不需要反向求导更新参数   \n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction = 'sum') # 将一批的损失相加\n",
    "            pred = output.max(1, keepdim = True)[1] # 概率最大的下标\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item() # 预测正确的数目\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(\"\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%) \\n\".format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100.* correct / len(test_loader.dataset)\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T14:51:56.981349Z",
     "start_time": "2020-06-01T14:46:14.899109Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [14848/60000 (25%)]\tLoss: 0.294284\n",
      "Train Epoch: 1 [30208/60000 (50%)]\tLoss: 0.129229\n",
      "Train Epoch: 1 [45568/60000 (75%)]\tLoss: 0.116268\n",
      "\n",
      "Test set: Average loss: 0.0947, Accuracy: 9704/10000 (97%) \n",
      "\n",
      "Train Epoch: 2 [14848/60000 (25%)]\tLoss: 0.101943\n",
      "Train Epoch: 2 [30208/60000 (50%)]\tLoss: 0.069134\n",
      "Train Epoch: 2 [45568/60000 (75%)]\tLoss: 0.057888\n",
      "\n",
      "Test set: Average loss: 0.0560, Accuracy: 9828/10000 (98%) \n",
      "\n",
      "Train Epoch: 3 [14848/60000 (25%)]\tLoss: 0.043272\n",
      "Train Epoch: 3 [30208/60000 (50%)]\tLoss: 0.045392\n",
      "Train Epoch: 3 [45568/60000 (75%)]\tLoss: 0.061826\n",
      "\n",
      "Test set: Average loss: 0.0481, Accuracy: 9839/10000 (98%) \n",
      "\n",
      "Train Epoch: 4 [14848/60000 (25%)]\tLoss: 0.039544\n",
      "Train Epoch: 4 [30208/60000 (50%)]\tLoss: 0.050664\n",
      "Train Epoch: 4 [45568/60000 (75%)]\tLoss: 0.047017\n",
      "\n",
      "Test set: Average loss: 0.0471, Accuracy: 9840/10000 (98%) \n",
      "\n",
      "Train Epoch: 5 [14848/60000 (25%)]\tLoss: 0.055987\n",
      "Train Epoch: 5 [30208/60000 (50%)]\tLoss: 0.022167\n",
      "Train Epoch: 5 [45568/60000 (75%)]\tLoss: 0.043058\n",
      "\n",
      "Test set: Average loss: 0.0332, Accuracy: 9881/10000 (99%) \n",
      "\n",
      "Train Epoch: 6 [14848/60000 (25%)]\tLoss: 0.017528\n",
      "Train Epoch: 6 [30208/60000 (50%)]\tLoss: 0.021266\n",
      "Train Epoch: 6 [45568/60000 (75%)]\tLoss: 0.027909\n",
      "\n",
      "Test set: Average loss: 0.0375, Accuracy: 9875/10000 (99%) \n",
      "\n",
      "Train Epoch: 7 [14848/60000 (25%)]\tLoss: 0.014759\n",
      "Train Epoch: 7 [30208/60000 (50%)]\tLoss: 0.007498\n",
      "Train Epoch: 7 [45568/60000 (75%)]\tLoss: 0.025736\n",
      "\n",
      "Test set: Average loss: 0.0354, Accuracy: 9881/10000 (99%) \n",
      "\n",
      "Train Epoch: 8 [14848/60000 (25%)]\tLoss: 0.022110\n",
      "Train Epoch: 8 [30208/60000 (50%)]\tLoss: 0.013133\n",
      "Train Epoch: 8 [45568/60000 (75%)]\tLoss: 0.007603\n",
      "\n",
      "Test set: Average loss: 0.0290, Accuracy: 9901/10000 (99%) \n",
      "\n",
      "Train Epoch: 9 [14848/60000 (25%)]\tLoss: 0.008798\n",
      "Train Epoch: 9 [30208/60000 (50%)]\tLoss: 0.010545\n",
      "Train Epoch: 9 [45568/60000 (75%)]\tLoss: 0.010159\n",
      "\n",
      "Test set: Average loss: 0.0296, Accuracy: 9894/10000 (99%) \n",
      "\n",
      "Train Epoch: 10 [14848/60000 (25%)]\tLoss: 0.004983\n",
      "Train Epoch: 10 [30208/60000 (50%)]\tLoss: 0.008349\n",
      "Train Epoch: 10 [45568/60000 (75%)]\tLoss: 0.003801\n",
      "\n",
      "Test set: Average loss: 0.0347, Accuracy: 9893/10000 (99%) \n",
      "\n",
      "Train Epoch: 11 [14848/60000 (25%)]\tLoss: 0.008199\n",
      "Train Epoch: 11 [30208/60000 (50%)]\tLoss: 0.008878\n",
      "Train Epoch: 11 [45568/60000 (75%)]\tLoss: 0.010371\n",
      "\n",
      "Test set: Average loss: 0.0324, Accuracy: 9903/10000 (99%) \n",
      "\n",
      "Train Epoch: 12 [14848/60000 (25%)]\tLoss: 0.004966\n",
      "Train Epoch: 12 [30208/60000 (50%)]\tLoss: 0.002692\n",
      "Train Epoch: 12 [45568/60000 (75%)]\tLoss: 0.023309\n",
      "\n",
      "Test set: Average loss: 0.0340, Accuracy: 9899/10000 (99%) \n",
      "\n",
      "Train Epoch: 13 [14848/60000 (25%)]\tLoss: 0.004863\n",
      "Train Epoch: 13 [30208/60000 (50%)]\tLoss: 0.003811\n",
      "Train Epoch: 13 [45568/60000 (75%)]\tLoss: 0.001478\n",
      "\n",
      "Test set: Average loss: 0.0383, Accuracy: 9880/10000 (99%) \n",
      "\n",
      "Train Epoch: 14 [14848/60000 (25%)]\tLoss: 0.001667\n",
      "Train Epoch: 14 [30208/60000 (50%)]\tLoss: 0.004739\n",
      "Train Epoch: 14 [45568/60000 (75%)]\tLoss: 0.002783\n",
      "\n",
      "Test set: Average loss: 0.0364, Accuracy: 9899/10000 (99%) \n",
      "\n",
      "Train Epoch: 15 [14848/60000 (25%)]\tLoss: 0.002694\n",
      "Train Epoch: 15 [30208/60000 (50%)]\tLoss: 0.005477\n",
      "Train Epoch: 15 [45568/60000 (75%)]\tLoss: 0.003478\n",
      "\n",
      "Test set: Average loss: 0.0378, Accuracy: 9898/10000 (99%) \n",
      "\n",
      "Train Epoch: 16 [14848/60000 (25%)]\tLoss: 0.003275\n",
      "Train Epoch: 16 [30208/60000 (50%)]\tLoss: 0.000894\n",
      "Train Epoch: 16 [45568/60000 (75%)]\tLoss: 0.001128\n",
      "\n",
      "Test set: Average loss: 0.0307, Accuracy: 9916/10000 (99%) \n",
      "\n",
      "Train Epoch: 17 [14848/60000 (25%)]\tLoss: 0.000831\n",
      "Train Epoch: 17 [30208/60000 (50%)]\tLoss: 0.008357\n",
      "Train Epoch: 17 [45568/60000 (75%)]\tLoss: 0.000516\n",
      "\n",
      "Test set: Average loss: 0.0331, Accuracy: 9914/10000 (99%) \n",
      "\n",
      "Train Epoch: 18 [14848/60000 (25%)]\tLoss: 0.000753\n",
      "Train Epoch: 18 [30208/60000 (50%)]\tLoss: 0.003003\n",
      "Train Epoch: 18 [45568/60000 (75%)]\tLoss: 0.002054\n",
      "\n",
      "Test set: Average loss: 0.0495, Accuracy: 9866/10000 (99%) \n",
      "\n",
      "Train Epoch: 19 [14848/60000 (25%)]\tLoss: 0.006133\n",
      "Train Epoch: 19 [30208/60000 (50%)]\tLoss: 0.000784\n",
      "Train Epoch: 19 [45568/60000 (75%)]\tLoss: 0.004594\n",
      "\n",
      "Test set: Average loss: 0.0419, Accuracy: 9894/10000 (99%) \n",
      "\n",
      "Train Epoch: 20 [14848/60000 (25%)]\tLoss: 0.001929\n",
      "Train Epoch: 20 [30208/60000 (50%)]\tLoss: 0.017033\n",
      "Train Epoch: 20 [45568/60000 (75%)]\tLoss: 0.002493\n",
      "\n",
      "Test set: Average loss: 0.0392, Accuracy: 9908/10000 (99%) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 总数据集的训练和测试\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(model,  DEVICE, train_loader, optimizer, epoch)\n",
    "    test(model, DEVICE, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "pytorch_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "161px",
    "width": "221px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}