## 神经元模型

神经元是神经网络中最基本的结构，也是构成神经网络的基本单元，其主要是模拟生物神经元的结构和特性，接收一组输入信号并产出
输出。它的设计灵感完全来源于生物学上神经元的信息传播机制。学过生物的同学都知道，神经元有两种状态：兴奋和抑制。一般情况下，大多数的神经元是处于抑制状态，但是一旦某个神经元收到刺激，导致它的电位超过一个**阈值**，那么这个神经元就会被激活，处于“兴奋”状态，进而向其他的神经元传播化学物质（其实就是信息）。

　　下图为生物学上的神经元结构示意图：

![1596362354](../img/神经网络基础/1596362354.jpg)

## 人工神经网络

**人工神经网络（**Artificial Neural Network，ANN）是指一系列受生物学和神经学启发的、为模拟人脑神经网络而设计的数学模型，它从结构、实现机理和功能上模拟人脑神经网络。这些模型主要是通过对人脑的神经元网络进行抽象，构建人工神经元，并按照一定拓扑结构来建立人工神经元之间的连接，来模拟生物神经网络。在人工智能领域，人工神经网络也常常简称为神经网络（Neural Network，NN）或神经模型（Neural Model）。

与生物神经元类似，人工神经网络由多个节点（人工神经元）互相连接而成，可以用来对数据之间的复杂关系进行建模。不同节点之间的连接被赋予了不同的权重，每个权重代表了一个节点对另一个节点的影响大小。每个节点代表一种特定函数，来自其他节点的信息经过其相应的权重综合计算，输入到一个激活函数中并得到一个新的活性值（兴奋或抑制）。从系统观点看，人工神经元网络是由大量神经元通过极其丰富和完善的连接而构成的自适应非线性动态系统。

1943年，McCulloch和Pitts根据上图的生物神经元结构用一种简单的模型进行了表示，提出了一种非常简单的神经元模型，也就是我们现在经常用到的“**M-P神经元**模型”，如下图所示：

![img](https://images2015.cnblogs.com/blog/764050/201606/764050-20160619112701960-1012598812.png)

　　从上图M-P神经元模型可以看出，神经元的输出
$$
y = f(\sum_{i=1}^{n}w_{i}x_{i} - \theta)
$$
　　其中$\theta$为我们之前提到的神经元的激活阈值，函数$f(⋅)$也被称为是**激活函数**，一共有$m$个输入$x_1,x_2,...,x_m$，$w_1,w_2,...w_m$位各输入的权重。如上图所示，函数$f(⋅)$可以用一个阶跃方程表示，大于阈值激活；否则则抑制。但是这样有点太粗暴，因为阶跃函数不光滑，不连续，不可导，因此我们更常用的方法是用sigmoid函数来表示函数函数$f(⋅)$。

　　sigmoid函数的表达式和分布图如下所示：

![img](https://images2015.cnblogs.com/blog/764050/201606/764050-20160619132616585-890841084.png)
$$
f(x) = \frac{1}{1+e^{-x}}
$$

**激活函数**在神经元中非常重要的。为了增强网络的表示能力和学习能力，激活函数需要具备以下几点性质：

1. 连续并可导（允许少数点上不可导）的非线性函数。可导的激活函数可以直接利用数值优化的方法来学习网络参数。
  
2. 激活函数及其导函数要尽可能的简单，有利于提高网络计算效率。

3. 激活函数的导函数的值域要在一个合适的区间内，不能太大也不能太小，否则会影响训练的效率和稳定性。

  

下面介绍几种在神经网络中常用的激活函数。

1. Sigmoid型函数	

   Sigmoid 型函数是指一类S型曲线函数，为两端饱和函数。常用的Sigmoid 型函数有Logistic 函数和Tanh 函数。

   

2. ReLU函数

   ReLU（Rectified Linear Unit，修正线性单元）[Nair et al., 2010]，也叫Rectifier 函数[Glorot et al., 2011]，是目前深层神经网络中经常使用的激活函数。ReLU实际上是一个斜坡（ramp）函数，定义为
   $$
   ReLU(x)=
   \begin{cases}
       x & x \geq 0 \\
       0 & x \leq 0
   \end{cases}
   $$

   $$
   max(0,x)
   $$

   

3. 

  

## 感知机与神经网络

感知机（perceptron）是由两层神经元组成的结构，输入层用于接受外界输入信号，输出层（也被称为是感知机的功能层）就是M-P神经元。下图表示了一个输入层具有三个神经元（分别表示为$x_{0}$、$x_{1}$、$x_{2}$）的感知机结构：

![img](https://images2015.cnblogs.com/blog/764050/201606/764050-20160619145050085-1140057304.jpg)

　　根据上图不难理解，感知机模型可以由如下公式表示：
$$
y = f(wx + b)
$$
其中，$w$为感知机输入层到输出层连接的权重，$b$表示输出层的偏置

## 多层感知机

