# 基础概念

假设我们收集了一批西瓜的数据，例如：（色泽=青绿;根蒂=蜷缩;敲声=浊响)， (色泽=乌黑;根蒂=稍蜷;敲声=沉闷)， (色泽=浅自;根蒂=硬挺;敲声=清脆)……每对括号内是一个西瓜的记录，定义：	 

 - 所有记录的集合为：**数据集**。

 - 每一条记录为：一个实例（instance）或样本（sample）。

 - 例如：色泽或敲声，单个的特点为**特征**（feature）或**属性**（attribute）。

 - 对于一条记录，如果在坐标轴上表示，每个西瓜都可以用坐标轴中的一个点表示，一个点也是一个向量，例如（青绿，蜷缩，浊响），即每个西瓜为：一个特征向量（feature vector）。

 - 一个样本的特征数为：维数（dimensionality），该西瓜的例子维数为3，当维数非常大时，也就是现在说的“维数灾难”。

   计算机程序学习经验数据生成算法模型的过程中，每一条记录称为一个“训练样本”，同时在训练好模型后，我们希望使用新的样本来测试模型的效果，则每一个新的样本称为一个“测试样本”。定义：	

 - 所有训练样本的集合为：**训练集**（trainning set），[特殊]。

 - 所有测试样本的集合为：**测试集**（test set），[一般]。  

 - 机器学习出来的模型适用于新样本的能力为：**泛化能力**（generalization），即从特殊到一般。

   西瓜的例子中，我们是想计算机通过学习西瓜的特征数据，训练出一个决策模型，来判断一个新的西瓜是否是好瓜。可以得知我们预测的是：西瓜是好是坏，即好瓜与差瓜两种，是离散值。同样地，也有通过历年的人口数据，来预测未来的人口数量，人口数量则是连续值。定义：	

 - 预测值为**离散值**的问题为：**分类**（classification）。

 - 预测值为**连续值**的问题为：**回归**（regression）。

   我们预测西瓜是否是好瓜的过程中，很明显对于训练集中的西瓜，我们事先已经知道了该瓜是否是好瓜，学习器通过学习这些好瓜或差瓜的特征，从而总结出规律，即训练集中的西瓜我们都做了标记，称为标记信息。但也有没有标记信息的情形，例如：我们想将一堆西瓜根据特征分成两个小堆，使得某一堆的西瓜尽可能相似，即都是好瓜或差瓜，对于这种问题，我们事先并不知道西瓜的好坏，样本没有标记信息。定义：	

 - 训练数据**有标记**信息的学习任务为：**监督学习**（supervised learning），容易知道上面所描述的分类和回归都是监督学习的范畴。

 - 训练数据**没有标记**信息的学习任务为：**无监督学习**（unsupervised learning），常见的有聚类和关联规则。

------

我们将学习器对样本的实际预测结果与样本的真实值之间的差异成为：**误差**（error）。定义：	

 - 在训练集上的误差称为训练误差（training error）或经验误差（empirical error）。
 - 在测试集上的误差称为测试误差（test error）。
 - 学习器在所有新样本上的误差称为泛化误差（generalization error）。

显然，我们希望得到的是在新样本上表现得很好的学习器，即泛化误差小的学习器。因此，我们应该让学习器尽可能地从训练集中学习出具有普遍适应的“一般特征”，这样在遇到新样本时才能做出正确的判别。然而，当学习器把训练集学得“太好”的时候，即把一些训练样本的自身特点当做了普遍特征；同时也有学习能力不足（学的太差）的情况，即训练集的基本特征都没有学习出来。我们定义：

 - 学习能力过强，以至于把训练样本所包含的不太一般的特性都学到了，称为：**过拟合（overfitting）**。
 - 学习能太差，训练样本的一般性质尚未学好，称为：**欠拟合（underfitting）**。

可以得知：在过拟合问题中，训练误差十分小，但测试误差教大；在欠拟合问题中，训练误差和测试误差都比较大。目前，欠拟合问题比较容易克服，例如增加迭代次数等，但过拟合问题还没有十分好的解决方案，过拟合是机器学习面临的关键障碍。

![](https://i.loli.net/2018/10/17/5bc7181172996.png)

------

**评估指标/性能度量**

>评估指标即是我们对于一个模型效果的数值型量化。（有点类似与对于一个商品评价打分，而这是针对于模型效果和理想效果之间的一个打分）
>
>性能度量（performance measure）是衡量模型泛化能力的评价标准，在对比不同模型的能力时，使用不同的性能度量往往会导致不同的评判结果。

一般来说分类和回归问题的评价指标有如下一些形式：

**分类算法常见评估指标**：

* 对于二类分类器/分类算法，评价指标主要有accuracy， [Precision，Recall，F-score，Pr曲线]，ROC-AUC曲线。
* 对于多类分类器/分类算法，评价指标主要有accuracy， [宏平均和微平均，F-score]。

**回归预测类常见评估指标**:

平均绝对误差（Mean Absolute Error，MAE），**均方误差**（Mean Squared Error，MSE），平均绝对百分误差（Mean Absolute Percentage Error，MAPE），均方根误差（Root Mean Squared Error）， R2（R-Square）

* **平均绝对误差（Mean Absolute Error，MAE）**:平均绝对误差，其能更好地反映预测值与真实值误差的实际情况，其计算公式如下：

$$
MAE=\frac{1}{N} \sum_{i=1}^{N}\left|y_{i}-\hat{y}_{i}\right|
$$

+ **均方误差（Mean Squared Error，MSE）**,均方误差,其计算公式为：

$$
MSE=\frac{1}{N} \sum_{i=1}^{N}\left(y_{i}-\hat{y}_{i}\right)^{2}
$$

+ **R2（R-Square）**：
  
  残差平方和：
  $$
  SS_{res}=\sum\left(y_{i}-\hat{y}_{i}\right)^{2}
  $$
  总平均值:
  $$
  SS_{tot}=\sum\left(y_{i}-\overline{y}_{i}\right)^{2}
  $$
  其中$\overline{y}$表示$y$的平均值
  得到$R^2$表达式为：
  $$
  R^{2}=1-\frac{SS_{res}}{SS_{tot}}=1-\frac{\sum\left(y_{i}-\hat{y}_{i}\right)^{2}}{\sum\left(y_{i}-\overline{y}\right)^{2}}
  $$
  $R^2$用于度量因变量的变异中可由自变量解释部分所占的比例，取值范围是 0~1，$R^2$越接近1,表明回归平方和占总平方和的比例越大,回归线与各观测点越接近，用x的变化来解释y值变化的部分就越多,回归的拟合程度就越好。所以$R^2$也称为拟合优度（Goodness of Fit）的统计量。
  
  $y_{i}$表示真实值，$\hat{y}_{i}$表示预测值，$\overline{y}_{i}$表示样本均值。得分越高拟合效果越好。

**查准率/查全率/F1**

在分类问题中错误率和精度虽然常用，但不能满足所有的需求，例如：在推荐系统中，我们只关心推送给用户的内容用户是否感兴趣（即查准率），或者说所有用户感兴趣的内容我们推送出来了多少（即查全率）。因此，使用查准/查全率更适合描述这类问题。对于二分类问题，分类结果混淆矩阵与查准/查全率定义如下：

![4.png](https://i.loli.net/2018/10/17/5bc71daf885a4.png)

![5.png](https://i.loli.net/2018/10/17/5bc71daf871a6.png)

查准率和查全率是一对矛盾的度量。例如我们想让推送的内容尽可能用户全都感兴趣，那只能推送我们把握高的内容，这样就漏掉了一些用户感兴趣的内容，查全率就低了；如果想让用户感兴趣的内容都被推送，那只有将所有内容都推送上，宁可错杀一千，不可放过一个，这样查准率就很低了。

“P-R曲线”正是描述查准/查全率变化的曲线，**P-R曲线**定义如下：根据学习器的预测结果（一般为一个实值或概率）对测试样本进行排序，将最可能是“正例”的样本排在前面，最不可能是“正例”的排在后面，按此顺序逐个把样本作为“正例”进行预测，每次计算出当前的P值和R值，如下图所示：

![6.png](https://i.loli.net/2018/10/17/5bc71dafc4411.png)

P-R曲线如何评估呢？若一个学习器A的P-R曲线被另一个学习器B的P-R曲线完全包住，则称：B的性能优于A。若A和B的曲线发生了交叉，则谁的曲线下的面积大，谁的性能更优。但一般来说，曲线下的面积是很难进行估算的，所以衍生出了“平衡点”（Break-Event Point，简称BEP），即当P=R时的取值，平衡点的取值越高，性能更优。

P和R指标有时会出现矛盾的情况，这样就需要综合考虑他们，最常见的方法就是F-Measure，又称**F-Score**。F-Measure是P和R的加权调和平均，即：
$$
\frac{1}{F_\beta}=\frac{1}{1+\beta^2} \cdot  (\frac{1}{P}+\frac{\beta^2}{R})
$$

$$
F_\beta=\frac{(1+\beta^2) \times P \times R}{(\beta^2 \times P)+R}
$$

特别地，当β=1时，也就是常见的F1度量，是P和R的调和平均，当F1较高时，模型的性能越好。

![9.png](https://i.loli.net/2018/10/17/5bc71daf20885.png)

![10.png](https://i.loli.net/2018/10/17/5bc71daf4b90a.png)

有时候我们会有多个二分类混淆矩阵，例如：多次训练或者在多个数据集上训练，那么估算全局性能的方法有两种，分为宏观和微观。简单理解，宏观就是先算出每个混淆矩阵的P值和R值，然后取得平均P值macro-P和平均R值macro-R，在算出Fβ或F1，而微观则是计算出混淆矩阵的平均TP、FP、TN、FN，接着进行计算P、R，进而求出Fβ或F1。

![11.png](https://i.loli.net/2018/10/17/5bc71ed70230e.png)

**ROC与AUC**

如上所述：学习器对测试样本的评估结果一般为一个实值或概率，设定一个阈值，大于阈值为正例，小于阈值为负例，因此这个实值的好坏直接决定了学习器的泛化性能，若将这些实值排序，则排序的好坏决定了学习器的性能高低。ROC曲线正是从这个角度出发来研究学习器的泛化性能，ROC曲线与P-R曲线十分类似，都是按照排序的顺序逐一按照正例预测，不同的是ROC曲线以“真正例率”（True Positive Rate，简称TPR）为横轴，纵轴为“假正例率”（False Positive Rate，简称FPR），ROC偏重研究基于测试样本评估值的排序好坏。

![12.png](https://i.loli.net/2018/10/17/5bc71ed6bee91.png)

![13.png](https://i.loli.net/2018/10/17/5bc71ed75cefe.png)

简单分析图像，可以得知：当FN=0时，TN也必须0，反之也成立，我们可以画一个队列，试着使用不同的截断点（即阈值）去分割队列，来分析曲线的形状，（0,0）表示将所有的样本预测为负例，（1,1）则表示将所有的样本预测为正例，（0,1）表示正例全部出现在负例之前的理想情况，（1,0）则表示负例全部出现在正例之前的最差情况。限于篇幅，这里不再论述。

现实中的任务通常都是有限个测试样本，因此只能绘制出近似ROC曲线。绘制方法：首先根据测试样本的评估值对测试样本排序，接着按照以下规则进行绘制。

![14.png](https://i.loli.net/2018/10/17/5bc71ed740a24.png)

同样地，进行模型的性能比较时，若一个学习器A的ROC曲线被另一个学习器B的ROC曲线完全包住，则称B的性能优于A。若A和B的曲线发生了交叉，则谁的曲线下的面积大，谁的性能更优。ROC曲线下的面积定义为AUC（Area Uder ROC Curve），不同于P-R的是，这里的AUC是可估算的，即AOC曲线下每一个小矩形的面积之和。易知：AUC越大，证明排序的质量越好，AUC为1时，证明所有正例排在了负例的前面，AUC为0时，所有的负例排在了正例的前面。

![15.png](https://i.loli.net/2018/10/17/5bc71ed6e2c57.png)

**代价敏感错误率与代价曲线**

上面的方法中，将学习器的犯错同等对待，但在现实生活中，将正例预测成假例与将假例预测成正例的代价常常是不一样的，例如：将无疾病-->有疾病只是增多了检查，但有疾病-->无疾病却是增加了生命危险。以二分类为例，由此引入了“代价矩阵”（cost matrix）。

![16.png](https://i.loli.net/2018/10/17/5bc71ed6ed582.png)

在非均等错误代价下，我们希望的是最小化“总体代价”，这样“代价敏感”的错误率（2.5.1节介绍）为：

![17.png](https://i.loli.net/2018/10/17/5bc71ed70bebe.png)

同样对于ROC曲线，在非均等错误代价下，演变成了“代价曲线”，代价曲线横轴是取值在[0,1]之间的正例概率代价，式中p表示正例的概率，纵轴是取值为[0,1]的归一化代价。

![18.png](https://i.loli.net/2018/10/17/5bc71ed6e952e.png)

![19.png](https://i.loli.net/2018/10/17/5bc71ed6eee7b.png)

代价曲线的绘制很简单：设ROC曲线上一点的坐标为(TPR，FPR) ，则可相应计算出FNR，然后在代价平面上绘制一条从(0，FPR) 到(1，FNR) 的线段，线段下的面积即表示了该条件下的期望总体代价；如此将ROC 曲线土的每个点转化为代价平面上的一条线段，然后取所有线段的下界，围成的面积即为在所有条件下学习器的期望总体代价，如图所示：

![20.png](https://i.loli.net/2018/10/17/5bc71ed716e0d.png)

------

